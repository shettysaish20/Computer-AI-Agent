"""
Gemini LLM analyzer utility for grouped icon images
Sends Seraphine-generated grouped images to Gemini for intelligent analysis
"""

import os
import json
import asyncio
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from PIL import Image
from datetime import datetime
from utils.helpers import debug_print

try:
    from google import genai
    from google.genai.errors import ServerError
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    debug_print("⚠️  Warning: google-genai not installed. Gemini analysis will be skipped.")

try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    debug_print("⚠️  Warning: python-dotenv not installed. Make sure GEMINI_API_KEY is set manually.")


class GeminiIconAnalyzer:
    """
    Analyzes grouped icon images using Gemini LLM
    Takes Seraphine-generated final_*.png images and identifies icons with usage descriptions
    """
    
    def __init__(self, prompt_path: str = "utils/prompt.txt", 
                 output_dir: str = "outputs", 
                 max_concurrent_requests: int = 4,
                 save_results: bool = True):
        self.output_dir = output_dir
        self.prompt_path = prompt_path
        self.max_concurrent_requests = max_concurrent_requests
        self.save_results = save_results
        
        if not GEMINI_AVAILABLE:
            raise ImportError("google-genai package not installed. Install with: pip install google-genai")
        
        # Initialize Gemini client
        self.api_key = os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            raise ValueError("GEMINI_API_KEY not found in environment variables")
        
        self.client = genai.Client(api_key=self.api_key)
        self.prompt = self._load_prompt()
        
        debug_print(f"🤖 Gemini analyzer initialized with prompt from: {prompt_path}")
    
    def _load_prompt(self) -> str:
        """Load the analysis prompt from file"""
        try:
            with open(self.prompt_path, "r", encoding="utf-8") as f:
                prompt_content = f.read().strip()
            debug_print(f"✅ Loaded prompt ({len(prompt_content)} characters)")
            return prompt_content
        except FileNotFoundError:
            raise FileNotFoundError(f"Prompt file not found: {self.prompt_path}")
    
    async def analyze_grouped_images(self, grouped_image_paths: List[str] = None, 
                                   filename_base: str = None,
                                   direct_images: List[Tuple] = None) -> Dict[str, Any]:
        """
        Analyze grouped images generated by Seraphine
        
        Args:
            grouped_image_paths: List of paths to final_*.png images (traditional method)
            filename_base: Base filename for saving results
            direct_images: List of (PIL.Image, filename) tuples (optimized method)
            
        Returns:
            Dictionary containing analysis results
        """
        if direct_images:
            debug_print(f"\n🤖 Starting Gemini analysis of {len(direct_images)} grouped images (direct mode)...")
            valid_images = [(img, name) for img, name in direct_images if "combined" in name]
        else:
            debug_print(f"\n🤖 Starting Gemini analysis of {len(grouped_image_paths)} grouped images (file mode)...")
            valid_image_paths = [
                image_path for image_path in sorted(grouped_image_paths) 
                if "combined" in os.path.basename(image_path)
            ]
            valid_images = [(path, os.path.basename(path)) for path in valid_image_paths]
        
        if not valid_images:
            debug_print("❌ No valid combined images found for analysis")
            return {'images': [], 'total_icons': 0, 'analysis_time': 0}
        
        # Start timing
        start_time = datetime.now()
        
        debug_print(f"  📸 Starting parallel analysis of {len(valid_images)} images...")
        
        # Execute all tasks in parallel with concurrency limit
        semaphore = asyncio.Semaphore(self.max_concurrent_requests)
        
        # Modified analysis function with semaphore for direct images
        async def analyze_and_process_image_direct(image_data, filename: str, index: int) -> Dict[str, Any]:
            """Analyze a single image with concurrency control - supports both file paths and PIL images"""
            async with semaphore:
                debug_print(f"  📸 Analyzing image {index+1}/{len(valid_images)}: {filename}")
                
                try:
                    # Analyze with Gemini - supports both PIL and file path
                    response = await self._analyze_single_image_direct(image_data, filename)
                    
                    if response:
                        icons = self._parse_gemini_response(response)
                        
                        image_result = {
                            'image_path': filename if isinstance(image_data, str) else f"direct:{filename}",
                            'image_name': filename,
                            'icons_found': len(icons),
                            'icons': icons,
                            'raw_response': response,
                            'analysis_success': True
                        }
                        
                        debug_print(f"    ✅ Found {len(icons)} icons in {filename}")
                        return image_result
                    else:
                        image_result = {
                            'image_path': filename if isinstance(image_data, str) else f"direct:{filename}",
                            'image_name': filename,
                            'icons_found': 0,
                            'icons': [],
                            'raw_response': None,
                            'analysis_success': False,
                            'error': 'Failed to get response from Gemini'
                        }
                        debug_print(f"    ❌ Analysis failed for {filename}")
                        return image_result
                    
                except Exception as e:
                    debug_print(f"    ❌ Error analyzing {filename}: {str(e)}")
                    return {
                        'image_path': filename if isinstance(image_data, str) else f"direct:{filename}",
                        'image_name': filename,
                        'icons_found': 0,
                        'icons': [],
                        'raw_response': None,
                        'analysis_success': False,
                        'error': str(e)
                    }
        
        # Create tasks for all images
        tasks = []
        for i, (image_data, filename) in enumerate(valid_images):
            tasks.append(analyze_and_process_image_direct(image_data, filename, i))
        
        debug_print(f"🚀 Executing {len(tasks)} requests to Gemini (max {self.max_concurrent_requests} concurrent)...")
        image_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Handle any exceptions from gather
        processed_results = []
        total_icons_found = 0
        
        for i, result in enumerate(image_results):
            if isinstance(result, Exception):
                error_result = {
                    'image_path': f"direct:{valid_images[i][1]}" if direct_images else valid_images[i][0],
                    'image_name': valid_images[i][1],
                    'icons_found': 0,
                    'icons': [],
                    'raw_response': None,
                    'analysis_success': False,
                    'error': f'Task exception: {str(result)}'
                }
                processed_results.append(error_result)
                debug_print(f"    ❌ Task exception for {valid_images[i][1]}: {result}")
            else:
                processed_results.append(result)
                if result['analysis_success']:
                    total_icons_found += result['icons_found']
        
        image_results = processed_results
        
        end_time = datetime.now()
        analysis_duration = (end_time - start_time).total_seconds()
        
        # Compile final results
        results = {
            'filename_base': filename_base,
            'analysis_timestamp': end_time.isoformat(),
            'analysis_duration_seconds': analysis_duration,
            'total_images_analyzed': len(valid_images),
            'total_input_images': len(direct_images) if direct_images else len(grouped_image_paths),
            'analysis_mode': 'direct' if direct_images else 'file',
            'successful_analyses': len([r for r in image_results if r['analysis_success']]),
            'total_icons_found': total_icons_found,
            'images': image_results
        }
        
        # Save results
        results_path = self._save_analysis_results(results, filename_base)
        results['results_saved_to'] = results_path
        
        # Display summary
        self._display_analysis_summary(results)
        
        debug_print(f"🎉 Gemini analysis completed in {analysis_duration:.2f}s")
        return results
    
    async def _analyze_single_image_direct(self, image_data, filename: str) -> Optional[str]:
        """Analyze a single image with Gemini - supports both PIL images and file paths"""
        try:
            if isinstance(image_data, str):
                # Traditional file path method
                image = Image.open(image_data)
            else:
                # Direct PIL image method (optimization!)
                image = image_data
            
            # Call Gemini API
            response = await self.client.aio.models.generate_content(
                model="gemini-2.0-flash-exp",
                contents=[self.prompt, image],
            )
            
            return response.text
            
        except ServerError as e:
            debug_print(f"    ⚠️  Server error: {e}")
            return None
        except Exception as e:
            debug_print(f"    ❌ Analysis error: {e}")
            return None
    
    def _parse_gemini_response(self, response_text: str) -> List[Dict[str, str]]:
        """Parse Gemini response into structured icon data"""
        if not response_text:
            return []
        
        icons = []
        lines = response_text.strip().split('\n')
        
        for line in lines:
            line = line.strip()
            
            # Skip empty lines and lines that don't start with group identifiers
            if not line or not line.startswith(('H', 'V', 'U')):
                continue
            
            try:
                # Parse format: ID: "icon_name" | Usage: "brief explanation"
                if '|' in line and ':' in line:
                    id_part, usage_part = line.split('|', 1)
                    
                    # Extract ID and name
                    id_section = id_part.split(':', 1)
                    if len(id_section) == 2:
                        icon_id = id_section[0].strip()
                        icon_name = id_section[1].strip().strip('"')
                        
                        # Extract usage
                        usage = usage_part.replace('Usage:', '').strip().strip('"')
                        
                        icons.append({
                            'id': icon_id,
                            'name': icon_name,
                            'usage': usage,
                            'group_type': icon_id[0] if icon_id else 'unknown'  # H, V, or U
                        })
                        
            except Exception as e:
                debug_print(f"    ⚠️  Failed to parse line: '{line}' - {e}")
                continue
        
        return icons
    
    def _save_analysis_results(self, results: Dict[str, Any], filename_base: str) -> str:
        """Save analysis results to JSON file (only if enabled) - SINGLE FILE ONLY"""
        if not self.save_results:
            return None  # Skip saving if disabled
        
        current_time = datetime.now().strftime("%H-%M")
        
        # Save only ONE file with all the details (remove redundant summary)
        analysis_path = os.path.join(self.output_dir, f"{filename_base}_gemini_analysis_{current_time}.json")
        
        # Save complete results (with structured data AND raw responses for debugging)
        with open(analysis_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        debug_print(f"💾 Saved Gemini analysis: {os.path.basename(analysis_path)}")
        
        return analysis_path
    
    def _display_analysis_summary(self, results: Dict[str, Any]):
        """Display a formatted summary of analysis results"""
        debug_print(f"\n🤖 GEMINI ANALYSIS SUMMARY:")
        debug_print("=" * 60)
        debug_print(f"  📊 Images analyzed: {results['successful_analyses']}/{results['total_images_analyzed']}")
        debug_print(f"  🎯 Total icons found: {results['total_icons_found']}")
        debug_print(f"  ⏱️  Analysis time: {results['analysis_duration_seconds']:.2f}s")
        
        # Group icons by type
        icon_counts = {'H': 0, 'V': 0, 'U': 0}
        all_icons = []
        
        for image_result in results['images']:
            if image_result['analysis_success']:
                for icon in image_result['icons']:
                    all_icons.append(icon)
                    group_type = icon.get('group_type', 'U')
                    icon_counts[group_type] = icon_counts.get(group_type, 0) + 1
        
        debug_print(f"\n📋 ICON BREAKDOWN:")
        debug_print(f"  🔄 Horizontal groups (H): {icon_counts['H']} icons")
        debug_print(f"  📊 Vertical groups (V): {icon_counts['V']} icons") 
        debug_print(f"  🔍 Ungrouped (U): {icon_counts['U']} icons")
        
        # Show sample icons
        if all_icons:
            debug_print(f"\n🎨 SAMPLE ICONS FOUND:")
            for i, icon in enumerate(all_icons[:5]):  # Show first 5
                debug_print(f"  {icon['id']}: \"{icon['name']}\" | {icon['usage'][:50]}...")
            
            if len(all_icons) > 5:
                debug_print(f"  ... and {len(all_icons) - 5} more icons")
        
        debug_print("=" * 60)
